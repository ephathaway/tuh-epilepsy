{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sys import path\n",
    "path.insert(0, '..')\n",
    "from tuh_epilepsy.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in signal data with Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49963, 2500, 24) (49963,)\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "# Here we get separate arrays for features and answers\n",
    "features, answers = dataset()\n",
    "# Transpose `features` so we have\n",
    "# shape (samples, channels) for each instance\n",
    "features = features.transpose((0,2,1))\n",
    "print(features.shape, answers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44966, 2500, 24) (44966,) (4997, 2500, 24) (4997,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, answers, test_size=0.1, random_state=90)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 2491, 100)         24100     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2482, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 827, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 818, 160)          160160    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 809, 160)          256160    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 322       \n",
      "=================================================================\n",
      "Total params: 540,842\n",
      "Trainable params: 540,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "layers = tf.keras.layers\n",
    "model.add(layers.Conv1D(100, kernel_size=10, activation='relu', input_shape=input_shape))\n",
    "model.add(layers.Conv1D(100, kernel_size=10, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(160, kernel_size=10, activation='relu'))\n",
    "model.add(layers.Conv1D(160, kernel_size=10, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using training set to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40469 samples, validate on 4497 samples\n",
      "Epoch 1/50\n",
      "40469/40469 [==============================] - 1140s 28ms/step - loss: 6.8709 - acc: 0.5735 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 2/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 3/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 4/50\n",
      "40469/40469 [==============================] - 1142s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 5/50\n",
      "40469/40469 [==============================] - 1140s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 6/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 7/50\n",
      "40469/40469 [==============================] - 1140s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 8/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 9/50\n",
      "40469/40469 [==============================] - 1137s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 10/50\n",
      "40469/40469 [==============================] - 1137s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 11/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 12/50\n",
      "40469/40469 [==============================] - 1136s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 13/50\n",
      "40469/40469 [==============================] - 1136s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 14/50\n",
      "40469/40469 [==============================] - 1136s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 15/50\n",
      "40469/40469 [==============================] - 1136s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 16/50\n",
      "40469/40469 [==============================] - 1137s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 17/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 18/50\n",
      "40469/40469 [==============================] - 1137s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 19/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 20/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 21/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 22/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 23/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 24/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 25/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 26/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 27/50\n",
      "40469/40469 [==============================] - 1140s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 28/50\n",
      "40469/40469 [==============================] - 1141s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 29/50\n",
      "40469/40469 [==============================] - 1140s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 30/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 31/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 32/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 33/50\n",
      "40469/40469 [==============================] - 1137s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 34/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 35/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 36/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 37/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 38/50\n",
      "40469/40469 [==============================] - 1137s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 39/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 40/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 41/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 42/50\n",
      "40469/40469 [==============================] - 1140s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 43/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 44/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 45/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 46/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 47/50\n",
      "40469/40469 [==============================] - 1138s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 48/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 49/50\n",
      "40469/40469 [==============================] - 1139s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n",
      "Epoch 50/50\n",
      "40469/40469 [==============================] - 1140s 28ms/step - loss: 6.8732 - acc: 0.5736 - val_loss: 6.8135 - val_acc: 0.5773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56926.69, 'seconds')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "model.fit(x_train, y_train, validation_split=0.1, epochs=50, verbose=1)\n",
    "\n",
    "end = time.time()\n",
    "round(end - start, 2), 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.828498750441977, 0.5763458074904547]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model\n",
    "model.save('../tuh_epilepsy/resources/model_01.h5')\n",
    "# Measure accuracy for predictions on test data\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
